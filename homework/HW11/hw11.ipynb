{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64218d55",
   "metadata": {},
   "source": [
    "First, preprocess data and define first steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "729b71ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0+cpu\n",
      "GPU Available: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torchvision \n",
    "from torchvision import transforms \n",
    "\n",
    "\n",
    "print(torch.__version__)\n",
    "print(\"GPU Available:\", torch.cuda.is_available())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = \"cpu\" \n",
    "\n",
    "image_path = './'\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5), std=(0.5))\n",
    "])\n",
    "mnist_dataset = torchvision.datasets.MNIST(root=image_path, \n",
    "                                           train=True, \n",
    "                                           transform=transform, \n",
    "                                           download=True)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "## Set up the dataset\n",
    "from torch.utils.data import DataLoader\n",
    "mnist_dl = DataLoader(mnist_dataset, batch_size=batch_size, \n",
    "                      shuffle=True, drop_last=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fff426",
   "metadata": {},
   "source": [
    "Now define starting GAN - based on the sample code provided by Professor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62d574b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_network(input_size, n_filters):\n",
    "    model = nn.Sequential(\n",
    "        nn.ConvTranspose2d(input_size, n_filters*4, 4, 1, 0, \n",
    "                           bias=False),\n",
    "        nn.BatchNorm2d(n_filters*4),\n",
    "        nn.LeakyReLU(0.2),\n",
    "\n",
    "        nn.ConvTranspose2d(n_filters*4, n_filters*2, 3, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(n_filters*2),\n",
    "        nn.LeakyReLU(0.2),\n",
    "\n",
    "        nn.ConvTranspose2d(n_filters*2, n_filters, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(n_filters),\n",
    "        nn.LeakyReLU(0.2),\n",
    "\n",
    "        nn.ConvTranspose2d(n_filters, 1, 4, 2, 1, bias=False),\n",
    "        nn.Tanh())\n",
    "    return model\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, n_filters):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(1, n_filters, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(n_filters, n_filters*2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(n_filters * 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(n_filters*2, n_filters*4, 3, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(n_filters*4),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(n_filters*4, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, input):\n",
    "        output = self.network(input)\n",
    "        return output.view(-1, 1).squeeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9c075d",
   "metadata": {},
   "source": [
    "Remove one convolutional layer in both the generator and the discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed6d427f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReducedGenerator(nn.Module):\n",
    "    def __init__(self, input_size, n_filters):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            # z -> (n_filters*4, 4, 4)\n",
    "            nn.ConvTranspose2d(input_size, n_filters*4, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(n_filters*4),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            # (n_filters*4, 4, 4) -> (n_filters, 14, 14)\n",
    "            nn.ConvTranspose2d(n_filters*4, n_filters, 5, 3, 1, bias=False),\n",
    "            nn.BatchNorm2d(n_filters),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            # (n_filters, 14, 14) -> (1, 28, 28)\n",
    "            nn.ConvTranspose2d(n_filters, 1, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "\n",
    "class ReducedDiscriminator(nn.Module):\n",
    "    def __init__(self, n_filters):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            # (1, 28, 28) -> (n_filters, 14, 14)\n",
    "            nn.Conv2d(1, n_filters, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            # (n_filters, 14, 14) -> (n_filters*4, 7, 7)\n",
    "            nn.Conv2d(n_filters, n_filters*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(n_filters*4),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            # (n_filters*4, 7, 7) -> (1, 1, 1)\n",
    "            nn.Conv2d(n_filters*4, 1, 7, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.network(input)\n",
    "        return output.view(-1, 1).squeeze(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339a248c",
   "metadata": {},
   "source": [
    "Add one convolutional layer in both the generator and the discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f0bc8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtendedGenerator(nn.Module):\n",
    "    def __init__(self, input_size, n_filters):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            # z -> (n_filters*8, 2, 2)\n",
    "            nn.ConvTranspose2d(input_size, n_filters * 8, 2, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(n_filters * 8),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            # (n_filters*8, 2, 2) -> (n_filters*4, 4, 4)\n",
    "            nn.ConvTranspose2d(n_filters * 8, n_filters * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(n_filters * 4),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            # (n_filters*4, 4, 4) -> (n_filters*2, 7, 7)\n",
    "            nn.ConvTranspose2d(n_filters * 4, n_filters * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(n_filters * 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            # (n_filters*2, 7, 7) -> (n_filters, 14, 14)\n",
    "            nn.ConvTranspose2d(n_filters * 2, n_filters, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(n_filters),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            # (n_filters, 14, 14) -> (1, 28, 28)\n",
    "            nn.ConvTranspose2d(n_filters, 1, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "\n",
    "class ExtendedDiscriminator(nn.Module):\n",
    "    def __init__(self, n_filters):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            # (1, 28, 28) -> (n_filters//2, 28, 28) ← extra layer\n",
    "            nn.Conv2d(1, n_filters // 2, 3, 1, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            # (n_filters//2, 28, 28) -> (n_filters, 14, 14)\n",
    "            nn.Conv2d(n_filters // 2, n_filters, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            # (n_filters, 14, 14) -> (n_filters*2, 7, 7)\n",
    "            nn.Conv2d(n_filters, n_filters * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(n_filters * 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            # (n_filters*2, 7, 7) -> (n_filters*4, 4, 4)\n",
    "            nn.Conv2d(n_filters * 2, n_filters * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(n_filters * 4),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            # (n_filters*4, 4, 4) -> (1, 1, 1)\n",
    "            nn.Conv2d(n_filters * 4, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x).view(-1, 1).squeeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e195a3",
   "metadata": {},
   "source": [
    "Functions for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19defe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_size = 100\n",
    "image_size = (28, 28)\n",
    "n_filters = 32\n",
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "mode_z = 'uniform'\n",
    "\n",
    "def create_noise(batch_size, z_size, mode_z):\n",
    "    if mode_z == 'uniform':\n",
    "        input_z = torch.rand(batch_size, z_size, 1, 1) * 2 - 1\n",
    "    elif mode_z == 'normal':\n",
    "        input_z = torch.randn(batch_size, z_size, 1, 1)\n",
    "    return input_z\n",
    "\n",
    "def create_samples(g_model, input_z):\n",
    "    g_output = g_model(input_z)\n",
    "    images = torch.reshape(g_output, (batch_size, *image_size))    \n",
    "    return (images + 1) / 2.0\n",
    "\n",
    "\n",
    "def train_gan(gen_class, disc_class, label, z_size=100, n_filters=32, \n",
    "              mode_z='uniform', num_epochs=10, batch_size=64):\n",
    "    print(f\"Training {label} GAN\")\n",
    "    \n",
    "    gen_model = gen_class(z_size, n_filters).to(device)\n",
    "    disc_model = disc_class(n_filters).to(device)\n",
    "\n",
    "    g_optimizer = torch.optim.Adam(gen_model.parameters(), 0.0003)\n",
    "    d_optimizer = torch.optim.Adam(disc_model.parameters(), 0.0002)\n",
    "    loss_fn = nn.BCELoss()\n",
    "    fixed_z = create_noise(batch_size, z_size, mode_z).to(device)\n",
    "\n",
    "    def d_train(x):\n",
    "        disc_model.zero_grad()\n",
    "        batch_size = x.size(0)\n",
    "        x = x.to(device)\n",
    "\n",
    "        d_labels_real = torch.ones(batch_size, 1, device=device)\n",
    "        d_proba_real = disc_model(x)\n",
    "        d_loss_real = loss_fn(d_proba_real, d_labels_real)\n",
    "\n",
    "        input_z = create_noise(batch_size, z_size, mode_z).to(device)\n",
    "        g_output = gen_model(input_z)\n",
    "        d_proba_fake = disc_model(g_output.detach())\n",
    "        d_labels_fake = torch.zeros(batch_size, 1, device=device)\n",
    "        d_loss_fake = loss_fn(d_proba_fake, d_labels_fake)\n",
    "\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        return d_loss.item()\n",
    "\n",
    "    def g_train(x):\n",
    "        gen_model.zero_grad()\n",
    "        batch_size = x.size(0)\n",
    "        input_z = create_noise(batch_size, z_size, mode_z).to(device)\n",
    "        g_labels_real = torch.ones((batch_size, 1), device=device)\n",
    "\n",
    "        g_output = gen_model(input_z)\n",
    "        d_proba_fake = disc_model(g_output)\n",
    "        g_loss = loss_fn(d_proba_fake, g_labels_real)\n",
    "\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        return g_loss.item()\n",
    "\n",
    "    epoch_samples = []\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        gen_model.train()\n",
    "        g_losses, d_losses = [], []\n",
    "        for x, _ in mnist_dl:\n",
    "            d_losses.append(d_train(x))\n",
    "            g_losses.append(g_train(x))\n",
    "\n",
    "        print(f\"{label} Epoch {epoch:03d} | Avg Losses >> G: {np.mean(g_losses):.4f} / D: {np.mean(d_losses):.4f}\")\n",
    "        gen_model.eval()\n",
    "        with torch.no_grad():\n",
    "            epoch_samples.append(create_samples(gen_model, fixed_z).cpu().numpy())\n",
    "    return epoch_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043e3ec3",
   "metadata": {},
   "source": [
    "Train the three models and compare results; unchanged from sample code, with a conv layer removed, and a conv layer added. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b85a2dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Original GAN\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m samples_original \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_gan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmake_generator_network\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDiscriminator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOriginal\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m samples_reduced  \u001b[38;5;241m=\u001b[39m train_gan(ReducedGenerator, ReducedDiscriminator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReduced\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m samples_extended \u001b[38;5;241m=\u001b[39m train_gan(ExtendedGenerator, ExtendedDiscriminator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtended\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[13], line 72\u001b[0m, in \u001b[0;36mtrain_gan\u001b[1;34m(gen_class, disc_class, label, z_size, n_filters, mode_z, num_epochs, batch_size)\u001b[0m\n\u001b[0;32m     70\u001b[0m g_losses, d_losses \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, _ \u001b[38;5;129;01min\u001b[39;00m mnist_dl:\n\u001b[1;32m---> 72\u001b[0m     d_losses\u001b[38;5;241m.\u001b[39mappend(\u001b[43md_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     73\u001b[0m     g_losses\u001b[38;5;241m.\u001b[39mappend(g_train(x))\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m03d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Avg Losses >> G: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(g_losses)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m / D: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(d_losses)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[13], line 44\u001b[0m, in \u001b[0;36mtrain_gan.<locals>.d_train\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     42\u001b[0m input_z \u001b[38;5;241m=\u001b[39m create_noise(batch_size, z_size, mode_z)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     43\u001b[0m g_output \u001b[38;5;241m=\u001b[39m gen_model(input_z)\n\u001b[1;32m---> 44\u001b[0m d_proba_fake \u001b[38;5;241m=\u001b[39m \u001b[43mdisc_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m d_labels_fake \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(batch_size, \u001b[38;5;241m1\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m     46\u001b[0m d_loss_fake \u001b[38;5;241m=\u001b[39m loss_fn(d_proba_fake, d_labels_fake)\n",
      "File \u001b[1;32mc:\\Users\\hanna\\ECE_548\\ece-548-ML\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hanna\\ECE_548\\ece-548-ML\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[10], line 39\u001b[0m, in \u001b[0;36mDiscriminator.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m---> 39\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\hanna\\ECE_548\\ece-548-ML\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hanna\\ECE_548\\ece-548-ML\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\hanna\\ECE_548\\ece-548-ML\\venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:240\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 240\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\hanna\\ECE_548\\ece-548-ML\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hanna\\ECE_548\\ece-548-ML\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\hanna\\ECE_548\\ece-548-ML\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hanna\\ECE_548\\ece-548-ML\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    548\u001b[0m     )\n\u001b[1;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "samples_original = train_gan(make_generator_network, Discriminator, \"Original\")\n",
    "samples_reduced  = train_gan(ReducedGenerator, ReducedDiscriminator, \"Reduced\")\n",
    "samples_extended = train_gan(ExtendedGenerator, ExtendedDiscriminator, \"Extended\")\n",
    "\n",
    "#visualization\n",
    "\n",
    "selected_epochs = [1, 2, 4, 10, 20]\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i, e in enumerate(selected_epochs):\n",
    "    for j, samples in enumerate([samples_original, samples_reduced, samples_extended]):\n",
    "        for k in range(5):\n",
    "            ax = fig.add_subplot(len(selected_epochs), 15, i*15 + j*5 + k + 1)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            if k == 0 and j == 0:\n",
    "                ax.set_ylabel(f\"Epoch {e}\", fontsize=12)\n",
    "            if i == 0 and k == 2:\n",
    "                ax.set_title([\"Original\", \"Reduced\", \"Extended\"][j], fontsize=12)\n",
    "            image = samples[e-1][k]\n",
    "            ax.imshow(image, cmap='gray_r')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"GAN Output Comparison by Architecture\", fontsize=16, y=1.02)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
